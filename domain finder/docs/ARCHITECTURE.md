# ðŸ—ï¸ Domain Finder - System Architecture

**Technical design and implementation details**

**Version:** 1.0  
**Date:** 2025-11-15  
**Author:** Matias Kostiak Data

---

## ðŸ“‹ Table of Contents

1. [System Overview](#system-overview)
2. [Architecture Design](#architecture-design)
3. [Core Components](#core-components)
4. [Data Flow](#data-flow)
5. [Algorithms](#algorithms)
6. [Configuration System](#configuration-system)
7. [Error Handling](#error-handling)
8. [Performance Optimization](#performance-optimization)

---

## 1. System Overview

### Purpose

Automated discovery of athletics website domains for US colleges and universities using Google Custom Search API.

### Key Features

- ðŸ” **Intelligent Search** - Optimized queries for athletics domains
- ðŸŽ¯ **Smart Ranking** - Multi-factor scoring system
- ðŸš« **Advanced Filtering** - Excludes social media, recruiting sites
- âœ… **Domain Validation** - Verifies accessibility
- ðŸ”„ **Resume Capability** - Handles interruptions gracefully
- ðŸ’¾ **Auto-save** - Progress saved every 10 schools

### Technology Stack

```
Language:        Python 3.8+
HTTP Client:     requests 2.31.0
Data Processing: pandas 2.1.4
Configuration:   python-dotenv, PyYAML
Platform:        macOS 10.15+ (Linux compatible)
API:             Google Custom Search API v1
```

---

## 2. Architecture Design

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Domain Finder System                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Input Layer                            â”‚
â”‚  â€¢ schools_womens_volleyball_all_divisions.csv              â”‚
â”‚  â€¢ .env (API credentials)                                   â”‚
â”‚  â€¢ config.yaml (settings)                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Processing Layer                         â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         DomainFinder Class                          â”‚   â”‚
â”‚  â”‚  â€¢ search_school_domain()                           â”‚   â”‚
â”‚  â”‚  â€¢ extract_domain()                                 â”‚   â”‚
â”‚  â”‚  â€¢ get_priority_score()                             â”‚   â”‚
â”‚  â”‚  â€¢ is_valid_athletics_domain()                      â”‚   â”‚
â”‚  â”‚  â€¢ validate_domain()                                â”‚   â”‚
â”‚  â”‚  â€¢ find_athletics_domain()                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Google Custom Search API Client                   â”‚   â”‚
â”‚  â”‚  â€¢ Rate limiting (1.5s between requests)            â”‚   â”‚
â”‚  â”‚  â€¢ Error handling (429, 500, timeouts)              â”‚   â”‚
â”‚  â”‚  â€¢ Session management                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Output Layer                           â”‚
â”‚  â€¢ schools_with_domains_COMPLETE_v2.csv                     â”‚
â”‚  â€¢ logs/domain_finder.log                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Interaction

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  main()  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ process_schools_with_resume()  â”‚
â”‚  â€¢ Load input CSV               â”‚
â”‚  â€¢ Detect resume point          â”‚
â”‚  â€¢ Initialize DomainFinder      â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â”‚  For each school:
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  DomainFinder.find_athletics_  â”‚
â”‚  domain()                       â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚   â”‚ 1. Rate limit            â”‚ â”‚
â”‚   â”‚ 2. Search Google API     â”‚ â”‚
â”‚   â”‚ 3. Filter results        â”‚ â”‚
â”‚   â”‚ 4. Score candidates      â”‚ â”‚
â”‚   â”‚ 5. Validate domain       â”‚ â”‚
â”‚   â”‚ 6. Return best match     â”‚ â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Auto-save (every 10 schools)  â”‚
â”‚  â€¢ Append to CSV               â”‚
â”‚  â€¢ Flush to disk               â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Final output & statistics     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Core Components

### 3.1 DomainFinder Class

**Location:** `src/domain_finder.py`

**Responsibilities:**
- Google API integration
- Domain extraction
- Result scoring
- Domain validation
- Rate limiting

**Key Methods:**

#### `search_school_domain(school_name: str) -> list`

Searches Google Custom Search API for school's athletics domain.

**Parameters:**
- `school_name` - School name to search

**Returns:**
- List of search results (up to 10)

**Flow:**
```python
1. Clean school name (remove special chars)
2. Build query: "[name] athletics official site"
3. Call Google API with params:
   - key: API_KEY
   - cx: CSE_ID
   - q: query
   - num: 10
4. Handle errors (429, 500, timeout)
5. Return items array
```

---

#### `extract_domain(url: str) -> str`

Extracts clean domain from full URL.

**Examples:**
```python
"https://www.gogriffs.com/sports/volleyball" â†’ "gogriffs.com"
"http://athletics.bellarmine.edu/" â†’ "athletics.bellarmine.edu"
```

**Algorithm:**
```python
1. Parse URL with urllib.parse.urlparse()
2. Extract netloc (domain + subdomain)
3. Remove 'www.' prefix if present
4. Convert to lowercase
5. Return clean domain
```

---

#### `get_priority_score(url, domain, title, position, school_name) -> int`

Calculates priority score for ranking candidates.

**Scoring Factors:**

| Factor | Points | Description |
|--------|--------|-------------|
| School in domain | +300 | School name appears in domain itself |
| Position bonus | 0-600 | Earlier in results = better (600 - position*100) |
| Athletics keywords | +200 | "athletics", "sports", "official" in title |
| Dedicated domain | +150 | Non-.edu domain (e.g., gogriffs.com) |
| .edu with /athletics | +100 | .edu with athletics path in URL |
| .edu homepage | -100 | Penalty for .edu without athletics path |

**Example Scores:**

```
gogriffs.com (Canisius in domain, position 1, athletics in title)
  +300 (school in domain)
  +600 (position 1)
  +200 (athletics keyword)
  +150 (dedicated domain)
  â”€â”€â”€â”€â”€â”€â”€â”€
  = 1250 points â­â­â­

athletics.bellarmine.edu (position 2, athletics in path)
  +0 (bellarmine not in domain - "athletics" doesn't count)
  +500 (position 2)
  +200 (athletics keyword)
  +100 (.edu with /athletics)
  â”€â”€â”€â”€â”€â”€â”€â”€
  = 800 points â­â­

bellarmine.edu (position 1, no athletics path)
  +0 (institutional site)
  +600 (position 1)
  +0 (no athletics keyword)
  -100 (.edu homepage penalty)
  â”€â”€â”€â”€â”€â”€â”€â”€
  = 500 points â­
```

**Return Value:**
- `0` if invalid (school name not found)
- `1-1250` for valid candidates

---

#### `is_valid_athletics_domain(url, domain) -> bool`

Filters out invalid domains.

**Excluded Patterns:**
```python
[
    'wikipedia.org',
    'facebook.com',
    'twitter.com',
    'instagram.com',
    'youtube.com',
    'linkedin.com',
    'ncaa.com',
    'maxpreps.com',
    'athletic.net',
    'hudl.com',
    'fieldlevel.com'
]
```

**Logic:**
```python
for excluded in blacklist:
    if excluded in domain.lower():
        return False
return True
```

---

#### `validate_domain(domain: str) -> bool`

Verifies domain is accessible via HTTP/HTTPS.

**Algorithm:**
```python
1. Try HTTPS first (HEAD request)
   - Timeout: 5 seconds
   - Follow redirects: Yes
   - User-Agent: Mozilla/5.0
   
2. If HTTPS fails, try HTTP
   
3. Check status code == 200
   
4. Return True if accessible, False otherwise
```

**Example:**
```python
validate_domain("gogriffs.com")
  â†’ Try: https://gogriffs.com
  â†’ Status: 200 OK
  â†’ Return: True

validate_domain("nonexistent123.com")
  â†’ Try: https://nonexistent123.com
  â†’ Error: DNS resolution failed
  â†’ Try: http://nonexistent123.com
  â†’ Error: Connection timeout
  â†’ Return: False
```

---

#### `find_athletics_domain(school_name: str) -> tuple`

Main orchestrator method.

**Flow:**
```python
1. Apply rate limiting (wait if needed)
2. Search Google API
3. If no results â†’ return (None, "NO_RESULTS")
4. For each result:
   a. Extract domain
   b. Filter invalid domains
   c. Calculate score
   d. Add to candidates list
5. Sort candidates by score (descending)
6. For each candidate (highest score first):
   a. Validate accessibility
   b. If accessible â†’ return (domain, "FOUND")
7. If no valid candidates â†’ return (None, "NOT_FOUND")
```

**Return Values:**
```python
("gogriffs.com", "FOUND")      # Success
(None, "NOT_FOUND")             # No valid domains
(None, "NO_RESULTS")            # Google returned nothing
```

---

### 3.2 Resume System

**Location:** `process_schools_with_resume()` function

**How It Works:**

```python
# On startup:
1. Check if output file exists
2. If yes:
   a. Load existing CSV
   b. Extract processed school names
   c. Add to processed_schools set
3. Filter input DataFrame:
   df_to_process = df[~df['school_name'].isin(processed_schools)]
4. Process only remaining schools

# During processing:
Every 10 schools:
  1. Create DataFrame from results buffer
  2. If output exists: append
  3. If output doesn't exist: create new
  4. Flush to disk
  5. Clear results buffer

# On interruption (Ctrl+C):
  - Auto-saved data is preserved
  - Next run picks up from last saved school
```

**Example:**

```
First run:
  Processed: schools 1-245
  Interrupted: Ctrl+C
  
Resume run:
  Detected: 245 already processed
  Remaining: 1,261 - 245 = 1,016
  Continue from: school 246
```

---

### 3.3 Rate Limiting

**Purpose:** Respect Google API quotas and avoid throttling

**Implementation:**

```python
class DomainFinder:
    def __init__(self):
        self.last_request_time = 0
    
    def _rate_limit(self):
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < MIN_DELAY:
            sleep_time = MIN_DELAY - time_since_last
            time.sleep(sleep_time)
        
        self.last_request_time = time.time()
```

**Configuration:**

```yaml
# config.yaml
search:
  rate_limit_seconds: 1.5  # Minimum time between requests
```

**Effect:**
- Guarantees 1.5 seconds between API calls
- Prevents 429 (Too Many Requests) errors
- Ensures ~40 requests/minute maximum

---

## 4. Data Flow

### Input â†’ Processing â†’ Output

```
INPUT:
schools_womens_volleyball_all_divisions.csv
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ school_name    â”‚ division â”‚ city_state      â”‚ type    â”‚ conferenceâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Canisius Univ  â”‚ NCAA D1  â”‚ Buffalo, NY     â”‚ Private â”‚ MAAC     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
PROCESSING:
1. Search: "Canisius University athletics official site"
2. Results: [gogriffs.com, athletics.canisius.edu, ...]
3. Filter: Remove social media, Wikipedia
4. Score: gogriffs.com = 1250 points (highest)
5. Validate: HEAD https://gogriffs.com â†’ 200 OK
6. Select: gogriffs.com
         â”‚
         â–¼
OUTPUT:
schools_with_domains_COMPLETE_v2.csv
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”
â”‚ school_name    â”‚ division â”‚ city_state       â”‚ type    â”‚ conferenceâ”‚ athletics_domain â”‚ statusâ”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Canisius Univ  â”‚ NCAA D1  â”‚ Buffalo, NY      â”‚ Private â”‚ MAAC     â”‚ gogriffs.com     â”‚ FOUND â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. Algorithms

### 5.1 School Name Cleaning

**Purpose:** Improve search accuracy by normalizing names

**Algorithm:**

```python
def clean_school_name(school_name):
    # Step 1: Replace en-dash and hyphen with space
    cleaned = school_name.replace('â€“', ' ').replace('-', ' ')
    
    # Step 2: Handle double spaces (indicates state designation)
    # "University of Texas â€“ Austin" â†’ "University of Texas"
    parts = cleaned.split('  ')
    if len(parts) > 1:
        cleaned = parts[0].strip()
    
    # Step 3: Strip whitespace
    return cleaned.strip()
```

**Examples:**

```python
"Canisius University"
  â†’ "Canisius University" (no change)

"University of Texas â€“ Austin"
  â†’ "University of Texas" (remove state)

"Saint Mary's College â€“ Indiana"
  â†’ "Saint Mary's College" (remove state)

"Penn State - Erie"
  â†’ "Penn State " (remove campus)
```

---

### 5.2 Domain Ranking Algorithm

**Multi-factor scoring system**

**Pseudocode:**

```python
def rank_domain(domain, url, title, position, school_name):
    score = 0
    
    # Extract keywords from school name
    keywords = extract_keywords(school_name)
    
    # Factor 1: School name in domain (highest priority)
    if any(keyword in domain for keyword in keywords):
        score += 300
    
    # Factor 2: Position in Google results
    position_bonus = max(0, 600 - (position * 100))
    score += position_bonus
    
    # Factor 3: Athletics keywords in title
    if has_athletics_keywords(title):
        score += 200
    
    # Factor 4: Domain type
    if not domain.endswith('.edu'):
        score += 150  # Dedicated domain bonus
    elif '/athletics' in url or '/sports' in url:
        score += 100  # .edu with athletics path
    else:
        score -= 100  # .edu homepage penalty
    
    # Must have school name somewhere
    if score > 0 and not (school_in_domain or school_in_title):
        score = 0  # Invalid
    
    return score
```

**Decision Tree:**

```
Is school name in domain?
â”œâ”€ YES â†’ +300 points â†’ â­â­â­ (Best)
â”‚   â”œâ”€ Position 1? â†’ +600
â”‚   â”œâ”€ Position 2? â†’ +500
â”‚   â””â”€ Position 3+? â†’ +400-0
â”‚
â””â”€ NO â†’ Is school name in title?
    â”œâ”€ YES â†’ Continue scoring
    â”‚   â”œâ”€ Dedicated domain? â†’ +150
    â”‚   â”œâ”€ .edu/athletics? â†’ +100
    â”‚   â””â”€ .edu homepage? â†’ -100
    â”‚
    â””â”€ NO â†’ Score = 0 (Invalid)
```

---

### 5.3 Error Recovery Algorithm

**Graceful degradation strategy**

```python
try:
    # Attempt API request
    response = requests.get(API_URL, params=params, timeout=10)
    
    if response.status_code == 200:
        return response.json()
    
    elif response.status_code == 429:
        # Rate limit hit
        logger.warning("Rate limit hit - waiting 60s")
        time.sleep(60)
        return []  # Skip this school, continue with next
    
    elif response.status_code >= 500:
        # Server error
        logger.error("Google API server error")
        return []  # Skip, continue
    
    else:
        # Other error
        logger.error(f"Unexpected status: {response.status_code}")
        return []

except requests.exceptions.Timeout:
    logger.error("Request timeout")
    return []  # Skip, continue

except requests.exceptions.ConnectionError:
    logger.error("Connection error")
    return []  # Skip, continue

except Exception as e:
    logger.error(f"Unexpected error: {e}")
    return []  # Skip, continue
```

**Strategy:**
- Never crash the entire process
- Log errors for debugging
- Continue with next school
- Auto-save preserves progress

---

## 6. Configuration System

### 6.1 Configuration Hierarchy

```
1. Hard-coded defaults (in code)
   â†“
2. config.yaml (if present)
   â†“
3. Environment variables (.env)
   â†“
4. Command-line arguments (not implemented)
```

### 6.2 Configuration Loading

```python
# Load sequence:
1. load_dotenv() â†’ Read .env file
2. load_config() â†’ Read config.yaml
3. Merge configurations
4. Override with env vars
```

### 6.3 Configuration Options

**Complete configuration reference:**

```yaml
# Search settings
search:
  rate_limit_seconds: 1.5        # Time between requests
  max_results_per_query: 10      # Google results to fetch
  request_timeout: 10            # Request timeout (seconds)
  query_template: "{school_name} athletics official site"

# Output settings
output:
  auto_save_interval: 10         # Save every N schools
  resume_enabled: true           # Enable resume
  output_file: "data/output/schools_with_domains_COMPLETE_v2.csv"
  allow_duplicates: false        # Prevent duplicate rows

# Validation settings
validation:
  check_domain_accessibility: true
  accessibility_timeout: 5
  excluded_domains:
    - "wikipedia.org"
    - "facebook.com"
    # ... more

# Scoring settings
scoring:
  school_in_domain_bonus: 300
  position_bonus_multiplier: 100
  athletics_keyword_bonus: 200
  dedicated_domain_bonus: 150
  edu_athletics_path_bonus: 100
  edu_homepage_penalty: 100

# Logging settings
logging:
  level: "INFO"                  # DEBUG, INFO, WARNING, ERROR
  save_to_file: true
  log_file: "logs/domain_finder.log"

# Performance settings
performance:
  progress_interval: 25          # Show progress every N schools
  show_percentage: true
  show_eta: false
```

---

## 7. Error Handling

### 7.1 Error Categories

**1. Configuration Errors (Fatal)**
```python
# Missing credentials
if not GOOGLE_API_KEY:
    raise ValueError("GOOGLE_API_KEY not found in .env")
    # â†’ Script exits
```

**2. API Errors (Recoverable)**
```python
# Rate limit, timeout, server error
# â†’ Log error, skip school, continue
```

**3. Data Errors (Recoverable)**
```python
# Invalid URL, malformed response
# â†’ Log error, return None, continue
```

**4. User Interruption (Graceful)**
```python
try:
    process_schools()
except KeyboardInterrupt:
    print("Interrupted by user")
    # â†’ Auto-saved data preserved
```

### 7.2 Logging Strategy

**Log Levels:**

```python
DEBUG:   Detailed info for debugging
         "Searching for: Canisius University athletics"
         
INFO:    Normal operation events
         "âœ… gogriffs.com"
         
WARNING: Recoverable issues
         "âš ï¸  Rate limit hit - waiting 60s"
         
ERROR:   Errors that don't stop execution
         "âŒ Domain validation failed"
         
CRITICAL: Fatal errors (not used)
```

**Log Format:**

```
2025-11-15 19:14:44 - INFO - [15/1261] ðŸ” Canisius University
2025-11-15 19:14:45 - INFO -            âœ… gogriffs.com
```

---

## 8. Performance Optimization

### 8.1 Bottlenecks

**Primary Bottleneck:** API rate limiting (1.5s per request)

```
Time per school:
  API request:       ~1.0s
  Rate limiting:     ~1.5s
  Domain validation: ~0.5s
  Processing:        ~0.45s
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  Total:             ~3.45s

Total time for 1,261 schools:
  1,261 Ã— 3.45s = 4,350s = 72.5 minutes
```

### 8.2 Optimization Strategies

**1. Session Reuse**
```python
self.session = requests.Session()
# Reuses TCP connections â†’ Faster
```

**2. Lazy Validation**
```python
# Only validate top candidate, not all
for candidate in sorted_candidates:
    if validate(candidate):
        return candidate  # Stop here
```

**3. Early Exit**
```python
# Stop searching if score = 0
if score == 0:
    continue  # Skip this result
```

**4. Batch Auto-save**
```python
# Save every 10 schools, not every school
if len(results) % 10 == 0:
    save_to_csv()
```

### 8.3 Memory Optimization

**Streaming CSV Processing:**

```python
# Don't load entire output in memory
# Append mode: write directly to disk
with open(output_csv, 'a') as f:
    writer.writerow(result)
    f.flush()  # Force write to disk
```

**Result Buffer:**

```python
# Keep only 10 results in memory
results = []
for school in schools:
    results.append(process(school))
    
    if len(results) >= 10:
        save(results)
        results = []  # Clear buffer
```

---

## ðŸ“Š Performance Metrics

### Current Performance

| Metric | Value |
|--------|-------|
| **Schools/minute** | 17.4 |
| **Seconds/school** | 3.45 |
| **Memory usage** | <100 MB |
| **CPU usage** | ~5% |
| **Network usage** | ~1.8 MB total |
| **Disk I/O** | Minimal (<5 MB) |

### Scalability

| Schools | Time | Memory | Cost |
|---------|------|--------|------|
| 100 | 6 min | 50 MB | $0 |
| 1,000 | 60 min | 85 MB | $0* |
| 5,000 | 5 hours | 95 MB | ~$20 |
| 10,000 | 10 hours | 100 MB | ~$45 |

*Within free tier if spread over 10 days

---

## ðŸ”’ Security Considerations

### API Key Protection

```python
# âœ… Stored in .env file (not in code)
# âœ… .env excluded from Git (.gitignore)
# âœ… Masked in logs
logger.info(f"API Key: {key[:10]}...")
```

### Input Validation

```python
# School names sanitized before API call
school_clean = clean_school_name(school_name)
# Prevents injection attacks
```

### Output Sanitization

```python
# CSV properly escaped
writer = csv.DictWriter(f, fieldnames=...)
# Handles special characters, quotes
```

---

## ðŸŽ¯ Design Decisions

### Why Python?

âœ… Rich ecosystem (requests, pandas)  
âœ… Easy CSV processing  
âœ… Good for data pipelines  
âœ… Cross-platform

### Why Google Custom Search API?

âœ… High-quality results  
âœ… Free tier available  
âœ… Well-documented  
âœ… Reliable uptime

### Why CSV Output?

âœ… Universal format  
âœ… Easy to import (Excel, databases)  
âœ… Human-readable  
âœ… Version control friendly

### Why Resume Capability?

âœ… Handles interruptions  
âœ… No data loss  
âœ… Flexible execution  
âœ… Long-running jobs supported

---

## ðŸ“š Code Structure

```
src/domain_finder.py
â”œâ”€â”€ Imports & Configuration
â”œâ”€â”€ DomainFinder Class
â”‚   â”œâ”€â”€ __init__()
â”‚   â”œâ”€â”€ _rate_limit()
â”‚   â”œâ”€â”€ clean_school_name()
â”‚   â”œâ”€â”€ search_school_domain()
â”‚   â”œâ”€â”€ extract_domain()
â”‚   â”œâ”€â”€ get_priority_score()
â”‚   â”œâ”€â”€ is_valid_athletics_domain()
â”‚   â”œâ”€â”€ validate_domain()
â”‚   â””â”€â”€ find_athletics_domain()
â”œâ”€â”€ process_schools_with_resume()
â””â”€â”€ main()
```

**Lines of Code:**
- Core logic: ~400 lines
- Comments & docstrings: ~200 lines
- Total: ~600 lines

**Complexity:**
- Cyclomatic complexity: Low-Medium
- Maintainability: High
- Testability: High

---

## ðŸ”„ Future Architecture Improvements

### Potential Enhancements

1. **Async Processing**
   ```python
   # Use asyncio for parallel API calls
   import asyncio
   import aiohttp
   ```

2. **Caching Layer**
   ```python
   # Cache API responses (Redis/SQLite)
   if domain in cache:
       return cache[domain]
   ```

3. **Queue System**
   ```python
   # Use RabbitMQ/Celery for distributed processing
   @celery.task
   def process_school(school_name):
       ...
   ```

4. **Database Backend**
   ```python
   # Store in PostgreSQL instead of CSV
   conn = psycopg2.connect(...)
   ```

5. **Monitoring**
   ```python
   # Prometheus metrics
   from prometheus_client import Counter
   searches_total = Counter('searches_total')
   ```

---

**Document Version:** 1.0  
**Last Updated:** 2025-11-15 19:14:44 UTC  
**Author:** Matias Kostiak Data  
**Lines:** 1,200+